{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pickle\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the root file path for the project\n",
    "file_path = r\"C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge training metadata and features\n",
    "train_metadata = pd.read_csv(os.path.join(file_path, \"data\", \"train\", \"train_metadata.csv\"))\n",
    "train_color_features = pd.read_csv(os.path.join(file_path, \"data\", \"train\", \"Features\", \"color_histogram.csv\"))\n",
    "train_pca_features = pd.read_csv(os.path.join(file_path, \"data\", \"train\", \"Features\", \"hog_pca.csv\"))\n",
    "train_additional_features = pd.read_csv(os.path.join(file_path, \"data\", \"train\", \"Features\", \"additional_features.csv\"))\n",
    "\n",
    "train_metadata = train_metadata.merge(train_color_features, on=\"image_path\", how=\"left\")\n",
    "train_metadata = train_metadata.merge(train_pca_features, on=\"image_path\", how=\"left\")\n",
    "train_metadata = train_metadata.merge(train_additional_features, on=\"image_path\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge test metadata and features\n",
    "test_metadata = pd.read_csv(os.path.join(file_path, \"data\", \"test\", \"test_metadata.csv\"))\n",
    "test_color_features = pd.read_csv(os.path.join(file_path, \"data\", \"test\", \"Features\", \"color_histogram.csv\"))\n",
    "test_pca_features = pd.read_csv(os.path.join(file_path, \"data\", \"test\", \"Features\", \"hog_pca.csv\"))\n",
    "test_additional_features = pd.read_csv(os.path.join(file_path, \"data\", \"test\", \"Features\", \"additional_features.csv\"))    \n",
    "\n",
    "test_metadata = test_metadata.merge(test_color_features, on=\"image_path\", how=\"left\")\n",
    "test_metadata = test_metadata.merge(test_pca_features, on=\"image_path\", how=\"left\")\n",
    "test_metadata = test_metadata.merge(test_additional_features, on=\"image_path\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(train_metadata.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train_metadata.columns if col not in [\"image_path\", \"id\", \"ClassId\"]]\n",
    "\n",
    "# First split for train set and holdout set\n",
    "train_meta, holdout_meta = train_test_split(\n",
    "    train_metadata, test_size=0.2, stratify=train_metadata['ClassId'], random_state=42\n",
    ")\n",
    "\n",
    "# only focus on the train set for now\n",
    "X = train_meta['image_path'].values\n",
    "y = train_meta['ClassId'].values\n",
    "\n",
    "X_test = test_metadata[features]\n",
    "test_metadata['ClassId'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the CNN modules\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from GTRSB_CNN import SimpleCNN\n",
    "from transform import transform\n",
    "\n",
    "# setup for 5 folds cross validation\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# initialise arrays to store cv validation, holdout set and test results\n",
    "n_classes = 43\n",
    "n_samples = len(train_meta)\n",
    "n_test = len(test_metadata)\n",
    "\n",
    "cnn_val_probs = np.zeros((n_samples, n_classes))\n",
    "xgb_val_probs = np.zeros((n_samples, n_classes))\n",
    "svm_val_probs = np.zeros((n_samples, n_classes))\n",
    "\n",
    "cnn_test_probs_folds = np.zeros((n_test, n_classes, n_folds))\n",
    "xgb_test_probs_folds = np.zeros((n_test, n_classes, n_folds))\n",
    "svm_test_probs_folds = np.zeros((n_test, n_classes, n_folds))\n",
    "\n",
    "cnn_holdout_preds_folds = np.zeros((len(holdout_meta), n_classes, n_folds))\n",
    "xgb_holdout_preds_folds = np.zeros((len(holdout_meta), n_classes, n_folds))\n",
    "svm_holdout_preds_folds = np.zeros((len(holdout_meta), n_classes, n_folds))\n",
    "\n",
    "# Start Inference!\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    # 1. CNN\n",
    "    cnn_model = SimpleCNN(num_classes=n_classes)\n",
    "    cnn_model.load_state_dict(torch.load(os.path.join(file_path, \"models\", \"cnn_models\", f'cnn_fold{fold+1}_best.pth'), map_location=device))\n",
    "    cnn_model.eval()\n",
    "    cnn_model.to(device)\n",
    "    # inference on validation fold\n",
    "    val_img_paths = train_meta.iloc[val_idx]['image_path'].values\n",
    "    val_imgs = [Image.open(os.path.join(file_path, \"data\", \"train\", p)).convert('RGB') for p in val_img_paths]\n",
    "    val_tensors = torch.stack([transform(img) for img in val_imgs]).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = cnn_model(val_tensors)\n",
    "        # use softmax layer to obtain the predicted probs for each class\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "    cnn_val_probs[val_idx] = probs\n",
    "    # inference on whole test set\n",
    "    test_img_paths = test_metadata['image_path'].values\n",
    "    test_imgs = [Image.open(os.path.join(file_path, \"data\", \"test\", p)).convert('RGB') for p in test_img_paths]\n",
    "    test_tensors = torch.stack([transform(img) for img in test_imgs]).to(device)\n",
    "    with torch.no_grad():\n",
    "        test_logits = cnn_model(test_tensors)\n",
    "        test_probs = torch.softmax(test_logits, dim=1).cpu().numpy()\n",
    "    cnn_test_probs_folds[:, :, fold] = test_probs\n",
    "    # inference on whole holdout set\n",
    "    holdout_img_paths = holdout_meta['image_path'].values\n",
    "    holdout_imgs = [Image.open(os.path.join(file_path, \"data\", \"train\", p)).convert('RGB') for p in holdout_img_paths]\n",
    "    holdout_tensors = torch.stack([transform(img) for img in holdout_imgs]).to(device)\n",
    "    with torch.no_grad():\n",
    "        holdout_logits = cnn_model(holdout_tensors)\n",
    "        holdout_probs = torch.softmax(holdout_logits, dim=1).cpu().numpy()\n",
    "    cnn_holdout_preds_folds[:, :, fold] = holdout_probs\n",
    "\n",
    "    # 2. XGB\n",
    "    with open(os.path.join(file_path, \"models\", \"xgb_models.pkl\"), \"rb\") as f:\n",
    "        xgb_models = pickle.load(f)\n",
    "    xgb_model = xgb_models[fold]\n",
    "    # inference on validation fold\n",
    "    val_xgb_feats = train_meta[features].iloc[val_idx]\n",
    "    xgb_preds = xgb_model.predict_proba(val_xgb_feats)\n",
    "    xgb_val_probs[val_idx] = xgb_preds\n",
    "    # inference on whole test set\n",
    "    test_xgb_feats = test_metadata[features]\n",
    "    xgb_test_probs = xgb_model.predict_proba(test_xgb_feats)\n",
    "    xgb_test_probs_folds[:, :, fold] = xgb_test_probs\n",
    "    # inference on whole holdout set\n",
    "    holdout_xgb_feats = holdout_meta[features]\n",
    "    xgb_holdout_probs = xgb_model.predict_proba(holdout_xgb_feats)\n",
    "    xgb_holdout_preds_folds[:, :, fold] = xgb_holdout_probs\n",
    "\n",
    "    # 3. SVM\n",
    "    # scaler fit on train, transform val and test\n",
    "    scaler = StandardScaler()\n",
    "    train_svm_feats = train_meta[features].iloc[train_idx]\n",
    "    val_svm_feats = train_meta[features].iloc[val_idx]\n",
    "    test_svm_feats = test_metadata[features]\n",
    "    train_svm_feats_scaled = scaler.fit_transform(train_svm_feats)\n",
    "    val_svm_feats_scaled = scaler.transform(val_svm_feats)\n",
    "    test_svm_feats_scaled = scaler.transform(test_svm_feats)\n",
    "\n",
    "    with open(os.path.join(file_path, \"models\", \"svm_models.pkl\"), \"rb\") as f:\n",
    "        svm_models = pickle.load(f)\n",
    "    svm_model = svm_models[fold]\n",
    "    # inference on validation fold\n",
    "    svm_preds = svm_model.predict_proba(val_svm_feats_scaled)\n",
    "    svm_val_probs[val_idx] = svm_preds\n",
    "    # inference on whole test set\n",
    "    svm_test_probs = svm_model.predict_proba(test_svm_feats_scaled)\n",
    "    svm_test_probs_folds[:, :, fold] = svm_test_probs\n",
    "    # inference on whole holdout set\n",
    "    holdout_svm_feats = holdout_meta[features]\n",
    "    holdout_svm_feats_scaled = scaler.transform(holdout_svm_feats)\n",
    "    svm_holdout_probs = svm_model.predict_proba(holdout_svm_feats_scaled)\n",
    "    svm_holdout_preds_folds[:, :, fold] = svm_holdout_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the OOF validation predicted probs as input to the meta model\n",
    "val_stack = np.concatenate([cnn_val_probs, xgb_val_probs, svm_val_probs], axis=1)\n",
    "y_val = y  # The label of 80% of training data\n",
    "\n",
    "# train the stacking model\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "meta_model.fit(val_stack, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on holdout set\n",
    "# Aggregated the holdout prediction of each 5 models\n",
    "cnn_holdout_probs = np.mean(cnn_holdout_preds_folds, axis=2) # output shape: (n_holdout, n_classes)\n",
    "xgb_holdout_probs = np.mean(xgb_holdout_preds_folds, axis=2) # output shape: (n_holdout, n_classes)\n",
    "svm_holdout_probs = np.mean(svm_holdout_preds_folds, axis=2) # output shape: (n_holdout, n_classes)\n",
    "\n",
    "holdout_stack = np.concatenate([cnn_holdout_probs, xgb_holdout_probs, svm_holdout_probs], axis=1)\n",
    "\n",
    "# Get the true labels in holdout set\n",
    "y_holdout = holdout_meta['ClassId'].values\n",
    "\n",
    "# Evaluate\n",
    "ensemble_holdout_preds = meta_model.predict(holdout_stack)\n",
    "print('Ensemble holdout acc:', accuracy_score(y_holdout, ensemble_holdout_preds))\n",
    "print('Ensemble holdout f1:', f1_score(y_holdout, ensemble_holdout_preds, average='macro'))\n",
    "\n",
    "# Store stacking ensemble validation result for visualisation\n",
    "save_dir = os.path.join(file_path, \"results\", \"sankey_data\")\n",
    "np.save(os.path.join(save_dir, \"holdout_y.npy\"), y_holdout)\n",
    "np.save(os.path.join(save_dir, \"ensemble_holdout_preds.npy\"), ensemble_holdout_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble holdout acc: 0.9899817850637522\n",
    "# Ensemble holdout f1: 0.9898522457678046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error visualisation\n",
    "\n",
    "wrong_idx = np.where(ensemble_holdout_preds != y_holdout)[0]\n",
    "\n",
    "# find corresponding images in holdout_meta\n",
    "wrong_samples = holdout_meta.iloc[wrong_idx].copy()\n",
    "wrong_samples['pred'] = ensemble_holdout_preds[wrong_idx]\n",
    "\n",
    "# show first 12 wrong samples\n",
    "N = min(12, len(wrong_samples))\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, (_, row) in enumerate(wrong_samples.head(N).iterrows()):\n",
    "    img_path = os.path.join(file_path, \"data\", \"train\", row['image_path'])\n",
    "    img = Image.open(img_path)\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"True: {row['ClassId']}\\nPred: {row['pred']}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = classification_report(y_holdout, ensemble_holdout_preds, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "print(report_df)\n",
    "\n",
    "class_rows = report_df.iloc[:-3, :]\n",
    "\n",
    "x = list(range(43))\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(x, class_rows['precision'], marker='o', label='Precision', color='#1f77b4')\n",
    "plt.plot(x, class_rows['recall'], marker='o', label='Recall', color='#2ca02c')\n",
    "plt.plot(x, class_rows['f1-score'], marker='o', label='F1-score', color='#ff7f0e')\n",
    "\n",
    "plt.axhline(report_df.loc['macro avg', 'f1-score'], color='gray', linestyle='--', label='Macro F1')\n",
    "plt.axhline(report_df.loc['weighted avg', 'f1-score'], color='orange', linestyle='--', label='Weighted F1')\n",
    "\n",
    "plt.xlabel('Class', fontsize=13)\n",
    "plt.ylabel('Score', fontsize=13)\n",
    "plt.title('Stacking Model Per-Class Precision, Recall, F1-score (with Macro/Weighted F1)', fontsize=15, pad=12)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(x, x, fontsize=11, rotation=0)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend(loc='lower left', fontsize=11, framealpha=0.85)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated the test prediction of each 5 models\n",
    "cnn_test_probs = np.mean(cnn_test_probs_folds, axis=2)  # output shape: (n_test, n_classes)\n",
    "svm_test_probs = np.mean(svm_test_probs_folds, axis=2)  # output shape: (n_test, n_classes)\n",
    "xgb_test_probs = np.mean(xgb_test_probs_folds, axis=2)  # output shape: (n_test, n_classes)\n",
    "\n",
    "test_stack = np.concatenate([cnn_test_probs, xgb_test_probs, svm_test_probs], axis=1)\n",
    "\n",
    "# use the stacking model to predict the test set\n",
    "final_preds = meta_model.predict(test_stack)\n",
    "\n",
    "# save the final ensemble model prediction\n",
    "test_metadata[\"ClassId\"] = final_preds\n",
    "test_metadata[[\"id\", \"ClassId\"]].to_csv(os.path.join(file_path, \"results\", \"submission_ensemble.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP30027_A2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
