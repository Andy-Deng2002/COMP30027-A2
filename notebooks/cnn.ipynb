{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file path to your own path of the project\n",
    "file_path = r\"C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=20):\n",
    "    \"\"\"\n",
    "     Train the model and record training/validation metrics for each epoch\n",
    "    \"\"\"\n",
    "    best_acc = 0\n",
    "    best_f1 = 0\n",
    "    best_model_state = None\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        all_train_labels = []\n",
    "        all_train_preds = []\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "            all_train_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(total_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        train_f1 = f1_score(all_train_labels, all_train_preds, average='macro')\n",
    "        train_f1s.append(train_f1)\n",
    "\n",
    "        # evaluate\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        all_val_labels = []\n",
    "        all_val_preds = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                preds = outputs.argmax(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "        val_accs.append(val_acc)\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='macro')\n",
    "        val_f1s.append(val_f1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss {total_loss:.5f}, Train Acc {train_acc:.5f}, Val Acc {val_acc:.5f}, Train F1 {train_f1:.5f}, Val F1 {val_f1:.5f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_state = model.state_dict()  # save current best model's parameters\n",
    "            best_val_preds = all_val_preds.copy()\n",
    "            best_val_labels = all_val_labels.copy()\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "\n",
    "    # return all data during training \n",
    "    return best_acc, best_f1, best_model_state, train_losses, train_accs, val_accs, train_f1s, val_f1s,  best_val_preds, best_val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inport self-defined CNN modules\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from GTRSB_CNN import SimpleCNN\n",
    "from TrafficDataset import TrafficSignDataset\n",
    "from transform import transform\n",
    "\n",
    "# read train data\n",
    "metadata = pd.read_csv(os.path.join(file_path, \"data\", \"train\", \"train_metadata.csv\"))\n",
    "\n",
    "# First split into train set and holdout set\n",
    "train_data, holdout_set = train_test_split(\n",
    "    metadata,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=metadata['ClassId'],\n",
    "    shuffle=True\n",
    ")\n",
    "print(len(holdout_set))\n",
    "# transform train set into compatible dataset format\n",
    "train_dataset = TrafficSignDataset(train_data, os.path.join(file_path, \"data\", \"train\"), transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 5 fold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = train_data['image_path'].values\n",
    "y = train_data['ClassId'].values\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "# initialise to record training data in epochs\n",
    "all_train_losses = []\n",
    "all_train_accs = []\n",
    "all_val_accs = []\n",
    "all_train_f1s = []\n",
    "all_val_f1s = []\n",
    "all_best_val_accs = []\n",
    "all_best_val_f1s = []\n",
    "\n",
    "# initial to save OOF validation prediction\n",
    "cnn_val_preds = np.zeros(len(train_data), dtype=int)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"=== Fold {fold+1} ===\")\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_subset, batch_size=64, shuffle=False, num_workers=2)\n",
    "    model = SimpleCNN(num_classes=43).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_val_acc, best_val_f1, best_model_state, train_losses, train_accs, val_accs, train_f1s, val_f1s, val_preds, val_labels = train_model(\n",
    "        model, criterion, optimizer, train_loader, val_loader, device, num_epochs=num_epochs\n",
    "    )\n",
    "    # save the best model in each folds\n",
    "    torch.save(best_model_state, os.path.join(file_path, \"models\", \"cnn_models\", f\"cnn_fold{fold+1}_best.pth\"))\n",
    "    all_train_losses.append(train_losses)\n",
    "    all_train_accs.append(train_accs)\n",
    "    all_val_accs.append(val_accs)\n",
    "    all_train_f1s.append(train_f1s)\n",
    "    all_val_f1s.append(val_f1s)\n",
    "    all_best_val_accs.append(best_val_acc)\n",
    "    all_best_val_f1s.append(best_val_f1)\n",
    "\n",
    "    cnn_val_preds[val_idx] = val_preds\n",
    "    \n",
    "    print(f\"Fold {fold+1} best val acc: {best_val_acc:.5f}, best val F1: {best_val_f1:.5f}\")\n",
    "\n",
    "# save the cnn validation prediction for visualisation\n",
    "save_dir = os.path.join(file_path, \"results\", \"sankey_data\")\n",
    "np.save(os.path.join(save_dir, \"cnn_val_pred_labels.npy\"), cnn_val_preds)\n",
    "\n",
    "print(\"Mean Val Acc: {:.5f}\".format(np.mean(all_best_val_accs)))\n",
    "print(\"Mean Val F1: {:.5f}\".format(np.mean(all_best_val_f1s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training curves\n",
    "epochs = range(1, len(all_train_losses[0]) + 1)\n",
    "n_folds = 5\n",
    "\n",
    "fig, axes = plt.subplots(n_folds, 3, figsize=(18, 4 * n_folds))\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    # Loss\n",
    "    ax = axes[fold, 0]\n",
    "    ax.plot(epochs, all_train_losses[fold], label='Train Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title(f'Fold {fold+1} Train Loss')\n",
    "    ax.legend()\n",
    "\n",
    "    # Accuracy\n",
    "    ax = axes[fold, 1]\n",
    "    ax.plot(epochs, all_train_accs[fold], label='Train Acc')\n",
    "    ax.plot(epochs, all_val_accs[fold], label='Val Acc')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(f'Fold {fold+1} Accuracy')\n",
    "    ax.legend()\n",
    "\n",
    "    # F1 Score\n",
    "    ax = axes[fold, 2]\n",
    "    ax.plot(epochs, all_train_f1s[fold], label='Train F1')\n",
    "    ax.plot(epochs, all_val_f1s[fold], label='Val F1')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('F1 Score')\n",
    "    ax.set_title(f'Fold {fold+1} F1 Score')\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('All Folds Training Curves', y=1.02, fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict = classification_report(y, cnn_val_preds, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "print(report_df)\n",
    "\n",
    "\n",
    "# only keep class rows (remove accuracy, macro avg, weighted avg)\n",
    "class_rows = report_df.iloc[:-3, :]\n",
    "\n",
    "x = list(range(43))\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(x, class_rows['precision'], marker='o', label='Precision', color='#1f77b4')\n",
    "plt.plot(x, class_rows['recall'], marker='o', label='Recall', color='#2ca02c')\n",
    "plt.plot(x, class_rows['f1-score'], marker='o', label='F1-score', color='#ff7f0e')\n",
    "\n",
    "plt.axhline(report_df.loc['macro avg', 'f1-score'], color='gray', linestyle='--', label='Macro F1')\n",
    "plt.axhline(report_df.loc['weighted avg', 'f1-score'], color='orange', linestyle='--', label='Weighted F1')\n",
    "\n",
    "plt.xlabel('Class', fontsize=13)\n",
    "plt.ylabel('Score', fontsize=13)\n",
    "plt.title('CNN Per-Class Precision, Recall, F1-score (with Macro/Weighted F1)', fontsize=15, pad=12)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(x, x, fontsize=11, rotation=0)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend(loc='lower left', fontsize=11, framealpha=0.85)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the output of the intermediate layer\n",
    "def get_feature_map(model, x):\n",
    "    with torch.no_grad():\n",
    "        x = model.conv1(x)\n",
    "        x = model.bn1(x)\n",
    "        x = model.relu(x)\n",
    "        x = model.pool(x)\n",
    "        x = model.res_block1(x)\n",
    "        x = model.res_block2(x)\n",
    "        x = model.conv4(x)\n",
    "        x = model.bn4(x)\n",
    "        return x.cpu()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# find sample images to visualise the feature maps\n",
    "img_paths = [\n",
    "    r'C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\\data\\train\\img_000062.jpg',\n",
    "    r'C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\\data\\train\\img_000065.jpg',\n",
    "    r'C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\\data\\train\\img_000067.jpg'\n",
    "]\n",
    "\n",
    "n_imgs = len(img_paths)\n",
    "n_channels = 8  # first 8 channels\n",
    "\n",
    "fig, axes = plt.subplots(n_imgs, n_channels, figsize=(2.2*n_channels, 2.2*n_imgs))\n",
    "\n",
    "for row, img_path in enumerate(img_paths):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    feature_map = get_feature_map(model, input_tensor).squeeze(0)  # [C, H, W]\n",
    "    for col in range(n_channels):\n",
    "        ax = axes[row, col] if n_imgs > 1 else axes[col]\n",
    "        ax.imshow(feature_map[col].detach().cpu().numpy(), cmap='viridis')\n",
    "        ax.axis('off')\n",
    "        if row == 0:\n",
    "            ax.set_title(f'Channel {col}')\n",
    "    if n_channels == 1:\n",
    "        axes[row].set_ylabel(f'Image {row+1}')\n",
    "    else:\n",
    "        axes[row, 0].set_ylabel(f'Image {row+1}', rotation=90, size='large')\n",
    "\n",
    "plt.suptitle('Feature Maps (First 8 Channels) for Multiple Images', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis and visualisation by Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The use of Grad-CAM is based on the following link:\n",
    "# https://github.com/jacobgil/pytorch-grad-cam/blob/master/cam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find images to visualise the Grad-CAM\n",
    "img_paths = [\n",
    "    r'C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\\data\\train\\img_000062.jpg',\n",
    "    r'C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\\data\\train\\img_000065.jpg',\n",
    "    r'C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\\data\\train\\img_000067.jpg',\n",
    "    r'C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\\data\\train\\img_005456.jpg',\n",
    "    r'C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\\data\\train\\img_005459.jpg',\n",
    "    r'C:\\Users\\xiluo\\Desktop\\UoM 2025 S1\\ML\\COMP30027 asmt2\\data\\train\\img_005460.jpg',\n",
    "]\n",
    "\n",
    "target_layers = [model.conv1, model.conv4]  # first and last conv layer\n",
    "\n",
    "n_imgs = len(img_paths)\n",
    "fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
    "\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    group = i // 3\n",
    "    row = i % 3\n",
    "    col_base = group * 3 \n",
    "\n",
    "    img_name = os.path.basename(img_path)\n",
    "    meta_row = metadata[metadata['image_path'] == img_name]\n",
    "    if not meta_row.empty:\n",
    "        true_label = meta_row['ClassId'].values[0]\n",
    "    else:\n",
    "        true_label = 'N/A'\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_resized = img.resize((64, 64))\n",
    "    input_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred_label = output.argmax(1).item()\n",
    "\n",
    "    # original image\n",
    "    axes[row, col_base].imshow(img_resized)\n",
    "    axes[row, col_base].axis('off')\n",
    "    axes[row, col_base].set_title(f'True: {true_label}\\nPred: {pred_label}')\n",
    "    axes[row, col_base].set_ylabel(f'Image {i+1}', rotation=90, size='large')\n",
    "\n",
    "    # Grad-CAMs\n",
    "    for j, target_layer in enumerate(target_layers):\n",
    "        cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "        grayscale_cam = cam(input_tensor=input_tensor)[0, :]\n",
    "        img_np = np.array(img_resized).astype(np.float32) / 255.0\n",
    "        visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "        axes[row, col_base + j + 1].imshow(visualization)\n",
    "        axes[row, col_base + j + 1].axis('off')\n",
    "        axes[row, col_base + j + 1].set_title(f'Grad-CAM conv{1 if j==0 else 4}')\n",
    "\n",
    "plt.suptitle('Grad-CAM conv1, Grad-CAM conv4 (Left: round speed limit, Right: triangular warning)', y=1.02)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('grad_cam_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find wrong predictions and visualize by Grad-CAM\n",
    "wrong_images = []\n",
    "wrong_true_labels = []\n",
    "wrong_pred_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(1)\n",
    "        wrong_mask = preds != labels\n",
    "        for i in range(imgs.size(0)):\n",
    "            if wrong_mask[i]:\n",
    "                wrong_images.append(imgs[i].cpu())\n",
    "                wrong_true_labels.append(labels[i].cpu().item())\n",
    "                wrong_pred_labels.append(preds[i].cpu().item())\n",
    "\n",
    "print(f\"Total wrong predictions: {len(wrong_images)}\")\n",
    "\n",
    "# Create a single figure for all images\n",
    "N = 5  # Number of wrong predictions to show\n",
    "target_layer = model.conv4\n",
    "\n",
    "fig, axes = plt.subplots(N, 3, figsize=(15, 4*N))\n",
    "plt.suptitle('Wrong Predictions Analysis', fontsize=16, y=1.02)\n",
    "\n",
    "for idx in range(min(N, len(wrong_images))):\n",
    "    # Process image and generate Grad-CAM\n",
    "    img_tensor = wrong_images[idx].unsqueeze(0).to(device)\n",
    "    true_label = wrong_true_labels[idx]\n",
    "    pred_label = wrong_pred_labels[idx]\n",
    "    \n",
    "    # Prepare original image\n",
    "    img_np = img_tensor.squeeze().cpu().numpy().transpose(1,2,0)\n",
    "    img_np = (img_np * 0.5) + 0.5  # reverse normalization\n",
    "    img_np = np.clip(img_np, 0, 1)\n",
    "    \n",
    "    # Generate Grad-CAM\n",
    "    cam = GradCAM(model=model, target_layers=[target_layer])\n",
    "    grayscale_cam = cam(input_tensor=img_tensor)[0, :]\n",
    "    visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)\n",
    "    \n",
    "    # Get sample image of predicted class\n",
    "    sample_row = metadata[metadata['ClassId'] == pred_label].sample(1)\n",
    "    pred_img_path = sample_row['image_path'].values[0]\n",
    "    pred_img = Image.open(os.path.join(file_path, \"data\", \"train\", pred_img_path)).convert('RGB')\n",
    "    pred_img = pred_img.resize((img_np.shape[1], img_np.shape[0]))\n",
    "    pred_img_np = np.array(pred_img).astype(np.float32) / 255.0\n",
    "    \n",
    "    # Plot in the grid\n",
    "    axes[idx, 0].imshow(img_np)\n",
    "    axes[idx, 0].set_title(f\"True: {true_label}, Pred: {pred_label}\")\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    axes[idx, 1].imshow(visualization)\n",
    "    axes[idx, 1].set_title(\"Grad-CAM\")\n",
    "    axes[idx, 1].axis('off')\n",
    "    \n",
    "    axes[idx, 2].imshow(pred_img_np)\n",
    "    axes[idx, 2].set_title(f\"Sample of Class {pred_label}\")\n",
    "    axes[idx, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on test set and holdout set (5-fold average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 43\n",
    "MODEL_DIR = os.path.join(file_path, \"models\", \"cnn_models\")\n",
    "\n",
    "# setup holdout and test set\n",
    "test_metadata = pd.read_csv(os.path.join(file_path, \"data\", \"test\", \"test_metadata.csv\"))\n",
    "test_metadata[\"ClassId\"] = 0\n",
    "test_dataset = TrafficSignDataset(test_metadata, os.path.join(file_path, \"data\", \"test\"), transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "n_test = len(test_metadata)\n",
    "holdout_dataset = TrafficSignDataset(holdout_set, os.path.join(file_path, \"data\", \"train\"), transform=transform)\n",
    "holdout_loader = DataLoader(holdout_dataset, batch_size=64, shuffle=False)\n",
    "n_holdout = len(holdout_set)\n",
    "\n",
    "# initialise to store the predictions on test and holdout\n",
    "test_probs_folds = np.zeros((n_test, NUM_CLASSES, 5))\n",
    "holdout_probs_folds = np.zeros((n_holdout, NUM_CLASSES, 5))\n",
    "\n",
    "for fold in range(5):\n",
    "    model = SimpleCNN(num_classes=NUM_CLASSES)\n",
    "    model_path = os.path.join(MODEL_DIR, f'cnn_fold{fold+1}_best.pth')\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # inference on Test set\n",
    "    fold_test_probs = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, _ in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            fold_test_probs.append(probs)\n",
    "    fold_test_probs = np.concatenate(fold_test_probs, axis=0)\n",
    "    test_probs_folds[:, :, fold] = fold_test_probs\n",
    "\n",
    "    # inference on Holdout set\n",
    "    fold_holdout_probs = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, _ in holdout_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            fold_holdout_probs.append(probs)\n",
    "    fold_holdout_probs = np.concatenate(fold_holdout_probs, axis=0)\n",
    "    holdout_probs_folds[:, :, fold] = fold_holdout_probs\n",
    "\n",
    "# average for models in each fold\n",
    "test_probs_mean = np.mean(test_probs_folds, axis=2)\n",
    "test_preds = np.argmax(test_probs_mean, axis=1)\n",
    "\n",
    "holdout_probs_mean = np.mean(holdout_probs_folds, axis=2)\n",
    "holdout_preds = np.argmax(holdout_probs_mean, axis=1)\n",
    "np.save(os.path.join(save_dir, \"cnn_holdout_pred_labels.npy\"), holdout_preds)\n",
    "\n",
    "# store test prediction\n",
    "test_metadata['ClassId'] = test_preds\n",
    "test_metadata[['id', 'ClassId']].to_csv(os.path.join(file_path, \"results\", \"submission_cnn.csv\"), index=False)\n",
    "print(\"âœ… Test set predictions saved to submission_cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate holdout performance\n",
    "y = holdout_set['ClassId']\n",
    "report_dict = classification_report(y, holdout_preds, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "print(report_df)\n",
    "\n",
    "# only keep class rows (remove accuracy, macro avg, weighted avg)\n",
    "class_rows = report_df.iloc[:-3, :]\n",
    "\n",
    "x = list(range(43))\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(x, class_rows['precision'], marker='o', label='Precision', color='#1f77b4')\n",
    "plt.plot(x, class_rows['recall'], marker='o', label='Recall', color='#2ca02c')\n",
    "plt.plot(x, class_rows['f1-score'], marker='o', label='F1-score', color='#ff7f0e')\n",
    "\n",
    "plt.axhline(report_df.loc['macro avg', 'f1-score'], color='gray', linestyle='--', label='Macro F1')\n",
    "plt.axhline(report_df.loc['weighted avg', 'f1-score'], color='orange', linestyle='--', label='Weighted F1')\n",
    "\n",
    "plt.xlabel('Class', fontsize=13)\n",
    "plt.ylabel('Score', fontsize=13)\n",
    "plt.title('CNN Per-Class Precision, Recall, F1-score (with Macro/Weighted F1)', fontsize=15, pad=12)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(x, x, fontsize=11, rotation=0)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend(loc='lower left', fontsize=11, framealpha=0.85)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the ensemble prediction as the final submission and copy to root directory\n",
    "!copy results\\submission_cnn.csv submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP30027_A2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
